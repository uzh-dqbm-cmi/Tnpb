{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df9c0cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from src.utils import get_char, outer_cross_val\n",
    "import numpy as np\n",
    "from src.utils import one_hot_encode\n",
    "from models.data_process import prepare_nonproto_features\n",
    "from models.dataset import ProtospacerDataset\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from models.data_process import get_datatensor_partitions, prepare_nonproto_features, generate_partition_datatensor\n",
    "from models.trainval_workflow import run_inference\n",
    "from src.utils import compute_eval_results_df\n",
    "from models.data_process import prepare_the_data_for_user_samples,get_data_ready_for_user_samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12b2484f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_opt = argparse.ArgumentParser(description='Argparser for data')\n",
    "cmd_opt.add_argument('-data_dir',  type=str, default = './data/', help = 'directory of the data')\n",
    "cmd_opt.add_argument('-target_dir',  type=str, default='processed',  help = 'folder name to save the processed data')\n",
    "cmd_opt.add_argument('-working_dir',  type=str, default = './', help = 'the main working directory')\n",
    "cmd_opt.add_argument('-data_name',  type=str, default='./', help = '')\n",
    "cmd_opt.add_argument('-feature_list',  type=str, help = 'list of feature names we are gonna consider')\n",
    "cmd_opt.add_argument('-random_seed', type=int,default=42)\n",
    "args, _ = cmd_opt.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9798b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "args.data_name = 'Endogenous_spacers_TnpB_list.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fc094aa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true target is not provided, the correlation and loss will be meaningless\n"
     ]
    }
   ],
   "source": [
    "data = prepare_the_data_for_user_samples(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ad3d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_protospacer, y, x_extended_f,x_non_protos_f = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b580c7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_prediction(tdir, num_runs=5):\n",
    "    l = []\n",
    "    for i in range(num_runs):\n",
    "        df = pd.read_csv(os.path.join(tdir, f'run_{i}','predictions_test.csv'))\n",
    "        if 'seq_id' not in df:\n",
    "            df['seq_id'] = list(range(0, df.shape[0]))\n",
    "        if 'Unnamed: 0' in df:\n",
    "            del df['Unnamed: 0']\n",
    "        df['run_num'] = i\n",
    "        l.append(df)\n",
    "    df = pd.concat(l, axis=0, ignore_index=True)\n",
    "    return df        \n",
    "    \n",
    "def compute_avg_predictions(df):\n",
    "    agg_df = df.groupby(by=['seq_id']).mean()\n",
    "    agg_df.reset_index(inplace=True)\n",
    "    for colname in ('run_num', 'Unnamed: 0'):\n",
    "        if colname in agg_df:\n",
    "            del agg_df[colname]\n",
    "    return agg_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7323f3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model: RNN, exp_name: protospacer, saved at ./output/RNN_v2/protospacer/train_val\n",
      "cpu\n",
      "test\n",
      "model_name: RNN\n",
      "the true target is not provided\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "test\n",
      "model_name: RNN\n",
      "the true target is not provided\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "test\n",
      "model_name: RNN\n",
      "the true target is not provided\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "test\n",
      "model_name: RNN\n",
      "the true target is not provided\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "test\n",
      "model_name: RNN\n",
      "the true target is not provided\n",
      "xxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "===============\n",
      "model prediction is saved at ./output/RNN_v2/protospacer/sample_test/avg_5fold_predictions.csv\n"
     ]
    }
   ],
   "source": [
    "gpu_index = 0\n",
    "res_desc = {}\n",
    "num_runs = 5 # number of trained model folds to use for prediction\n",
    "version=2\n",
    "for model_name in ['RNN']:#['CNN', 'RNN', 'Transformer']:\n",
    "    args.model_name =  model_name# {'RNN','CNN', 'Transformer'}\n",
    "    res_desc[model_name] = {}\n",
    "    for exp_name in ['protospacer']:\n",
    "        args.exp_name = exp_name\n",
    "        model_path = os.path.join(args.working_dir, \n",
    "                                  'output', \n",
    "                                  f'{model_name}_v{version}',\n",
    "                                  exp_name)\n",
    "        dpartitions, datatensor_partitions = get_data_ready_for_user_samples(data,\n",
    "                                                                             args,\n",
    "                                                                             num_runs=num_runs, # define how many model runs to be used\n",
    "                                                                             normalize_opt='max',\n",
    "                                                                             train_size=0., \n",
    "                                                                             fdtype=torch.float32)\n",
    "\n",
    "        train_val_path = os.path.join(model_path, 'train_val')\n",
    "        test_path = os.path.join(model_path, 'sample_test')\n",
    "        \n",
    "        print(f'Running model: {model_name}, exp_name: {exp_name}, saved at {train_val_path}')\n",
    "        a, b = run_inference(datatensor_partitions, \n",
    "                             train_val_path, \n",
    "                             test_path, \n",
    "                             gpu_index, \n",
    "                             to_gpu=True)\n",
    "                             #num_runs=num_runs)\n",
    "        print('='*15)\n",
    "        \n",
    "        # save all predictions in one dataframe with the corresponding model run\n",
    "        tdf = compile_prediction(test_path, num_runs=num_runs)\n",
    "        # compute average prediction across the different runs of the same model\n",
    "        tdf_ensemble = compute_avg_predictions(tdf)\n",
    "        tdf.to_csv(os.path.join(test_path, f'{num_runs}fold_predictions.csv'), index=False)\n",
    "        tdf_ensemble.to_csv(os.path.join(test_path, f'avg_{num_runs}fold_predictions.csv'), index=False)\n",
    "        print('model prediction is saved at',os.path.join(test_path, f'avg_{num_runs}fold_predictions.csv'))\n",
    "        #res_desc[model_name][exp_name] = compute_eval_results_df(test_path, len(dpartitions))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f6123",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
